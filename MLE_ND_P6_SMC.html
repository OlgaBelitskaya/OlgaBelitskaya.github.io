<!DOCTYPE HTML>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=0.9*device-width">
    <title>MLE_ND_P6_SMC</title>
    <script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script>
    <script>$(function () {
    sagecell.makeSagecell({inputLocation:'div.linked',linked:true,evalButtonText:'Run Linked Cells'});  
    sagecell.makeSagecell({inputLocation:'div.sage',evalButtonText:'Run'});
    });
    </script>
  </head>
  <style>
  @import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');
  body {background-color:honeydew;}; a, p {color:forestgreen; font-family:'Roboto';} 
  h1 {color:#31c831; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;} 
  h2, h3 {color:slategray; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;}
  h4 {color:#31c831; font-family:'Roboto';}
  .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
  .sagecell table.table_form tr.row-a {background-color:lightgray;} 
  .sagecell table.table_form tr.row-b {background-color:honeydew;}
  .sagecell table.table_form td {padding:5px 15px; color:forestgreen; font-family:'Roboto';}
  .sagecell_sessionOutput, .sagecell_sessionOutput pre {color:forestgreen; font-family:'Roboto';}
  </style>  
  <body>
    <h1>Machine Learning Engineer Nanodegree</h1>
    <h2>Capstone Project</h2>
    <h1>&#x1F4D1; &nbsp;P6: Sberbank Russian Housing Market</h1>
    <h2>Links and Code Library</h2>     
    <h3>Resources</h3>
<a href="https://scikit-learn.org/stable/index.html">&#x1F578;scikit-learn. Machine Learning in Python&nbsp;</a>
<a href="http://scipy-lectures.org/">&#x1F578;Scipy Lecture Notes&nbsp;</a><br/>
    <h3>Code Library</h3> 
<div class="linked"><script type="text/x-sage">
import numpy,pandas,pylab,seaborn,sympy; pylab.style.use('seaborn-whitegrid')
import warnings; from sklearn.exceptions import DataConversionWarning
for el in [FutureWarning,UserWarning,RuntimeWarning,DataConversionWarning]: warnings.filterwarnings("ignore",category=el)
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import mean_squared_error,median_absolute_error,mean_absolute_error,r2_score,explained_variance_score
from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor
from sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,ExtraTreesRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge,RidgeCV,BayesianRidge
from sklearn.linear_model import HuberRegressor,TheilSenRegressor,RANSACRegressor
from sklearn.preprocessing import OneHotEncoder,StandardScaler,RobustScaler,MinMaxScaler
</script></div>
    <p></p>
    <h3>Set of Functions</h3>
<div class="linked"><script type="text/x-sage">
def display_cat(df,feature):
    print ('\n'+'<_>'*30); print ('\n'+feature+': '+str(len(set(df[feature]))))
    sympy.pprint(set(df[feature]))
def regression(regressor,X_train,X_test,y_train):
    regressor.fit(X_train,y_train)
    return regressor.predict(x_train),regressor.predict(x_test)
def scores(regressor,y_train,y_test,y_train_reg,y_test_reg):
    separator1,separator2 = '<_>'*18,'-'*10
    print(separator1,'\n',regressor,'\n'+separator1)
    print("EV score. Train: ",explained_variance_score(y_train,y_train_reg))
    print("EV score. Test: ",explained_variance_score(y_test,y_test_reg))
    print(separator2)
    print("R2 score. Train: ",r2_score(y_train,y_train_reg))
    print("R2 score. Test: ",r2_score(y_test,y_test_reg))
    print(separator2)
    print("MSE score. Train: ",mean_squared_error(y_train,y_train_reg))
    print("MSE score. Test: ",mean_squared_error(y_test,y_test_reg))
    print(separator2)
    print("MAE score. Train: ",mean_absolute_error(y_train,y_train_reg))
    print("MAE score. Test: ",mean_absolute_error(y_test,y_test_reg))
    print(separator2)
    print("MdAE score. Train: ",median_absolute_error(y_train,y_train_reg))
    print("MdAE score. Test: ",median_absolute_error(y_test,y_test_reg))    
</script></div>
    <p></p>
    <h2>Capstone Proposal Overview</h2>
In this capstone project proposal, the goals are stated to leverage what we've learned throughout the Nanodegree Program for solving a problem of our choice by applying machine learning techniques.<br/> 
A project proposal encompasses seven key points.<br/>
<b>project's domain background</b>: the field of research where the project is derived;<br/>
<b>problem statement</b>: a problem being investigated for which a solution will be defined;<br/>
<b>datasets and inputs</b>: data or inputs being used for the problem;<br/>
<b>solution statement</b>: the solution proposed for the problem given;<br/>
<b>benchmark model</b>: some simple or historical model or result to compare the defined solution to;<br/>
<b>set of evaluation metrics</b>: functional representations for how the solution can be measured;<br/>
<b>outline of the project design</b>: how the solution will be developed and results obtained.<br/>
The full project report about results will be completed and published as well.
    <h2>Domain Background</h2>
Housing costs demand a significant investment from both consumers and developers. <br/>
And when it comes to planning a budget—whether personal or corporate—the last thing anyone needs is uncertainty about one of their budgets expenses. <br/>
Sberbank, Russia’s oldest and largest bank, helps their customers by making predictions about reality prices so renters, developers, <br/>and lenders are more confident when they sign a lease or purchase a building.<br/>
Although the housing market is relatively stable in Russia, the country’s volatile economy makes forecasting prices as a function of apartment characteristics a unique challenge. <br/>
Complex interactions between housing features such as a number of bedrooms and location are enough to make pricing predictions complicated. <br/>
Adding an unstable economy to the mix means Sberbank and their customers need more than simple regression models in their arsenal.
    <h2>Problem Statement</h2>
Sberbank is challenging programmers to develop algorithms which use a broad spectrum of features to predict real prices. <br/>Algorithm applications rely on a rich dataset that includes housing data and macroeconomic patterns.<br/> 
An accurate forecasting model will allow Sberbank to provide more certainty to their customers in an uncertain economy.<br/>
My choice of the solution in this situation is to select the most correlated indicators with the target variable and <br/>
apply ensemble algorithms that have repeatedly shown successful results in the study of price trends in real estate. <br/>
Boosting and bagging methods combine several models at once in order to improve the prediction accuracy on learning problems with a numerical target variable.<br/>
Then I'm going to explore different types of neural networks for regression predictions and try to achieve the same with ensemble methods level of model perfomance.
    <h2>Datasets and Inputs</h2>
The basis for the investigation is a large number of economic indicators for pricing and prices themselves (<i>train.csv</i> and <i>test.csv</i>).<br/>
Macroeconomic variables are collected in a separate file for transaction dates (<i>macro.csv</i>). <br/>
In addition, the detailed description of variables is provided (<i>data_dictionary.txt</i>).<br/>
For practical reasons, I have not analyzed all the data and have chosen the following independent variables:<br/>
- the dollar rate, which traditionally affects the Russian real estate market;<br/>
- the distance in km from the Kremlin (the closer to the center of the city, the more expensive);<br/>
- indicators characterizing the availability of urban infrastructure nearby (schools, medical and sports centers, supermarkets, etc.);<br/>
- indicators of a particular living space (number of rooms, floor, etc.);<br/>
- proximity to transport nodes (for example, to the metro);<br/>
- indicators of population density and employment in the region of housing accommodation.<br/>
All these economic indicators have a strong influence on price formation and can be used as a basic set for regression analysis.<br/> 
Examples of <b>numerical</b> variables: the distance to the metro, the distance to the school, the dollar rate at the transaction moment, the area of the living space. <br/>
Examples of <b>categorical</b> variables: neighborhoods, the nearest metro station, the number of rooms.<br/>
The goal of the project is to predict the price of housing using the chosen set of numerical and categorical variables.<br/> 
The predicted target isn't discrete, for the training set all the values of this dependent variable are given, and therefore it's necessary to apply regression algorithms of supervised learning.
    <h3>Data Description</h3>
<div class="sage"><script type="text/x-sage">
%%html
<div id="data"><iframe src="data_dictionary.txt" height="200" width="99%"></iframe></div>
</script></div>
    <p></p>
    <h3>Load and Display the Data</h3>      
<div class="linked"><script type="text/x-sage">
path='https://raw.githubusercontent.com/OlgaBelitskaya/machine_learning_engineer_nd009/master/Machine_Learning_Engineer_ND_P6/'
macro=pandas.read_csv(path+'macro.csv'); train=pandas.read_csv(path+'train.csv'); test=pandas.read_csv(path+'test.csv')
n1,n2,n3,n4=int(100),int(110),int(1),int(15)
macro[n1:n2].T[n3:n4]
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
train[n1:n2].T[n3:n4]
</script></div>
    <p></p>
    <h2>Solution Statement</h2>
    <h3>Selection of Features</h3>
    <p>Create lists of the features</p>
<div class="linked"><script type="text/x-sage">
X_list_num=['timestamp','full_sq','num_room','area_m','kremlin_km','big_road2_km','big_road1_km','workplaces_km',
            'stadium_km','swim_pool_km','fitness_km','detention_facility_km','cemetery_km','radiation_km','oil_chemistry_km',
            'theater_km','exhibition_km','museum_km','park_km','public_healthcare_km','metro_min_walk','metro_km_avto', 
            'bus_terminal_avto_km','public_transport_station_min_walk','railroad_station_walk_min','railroad_station_avto_km',
            'kindergarten_km','school_km','preschool_km','university_km','additional_education_km','shopping_centers_km',
            'big_market_km','ekder_all','work_all','young_all']
X_list_cat=['sub_area','ID_metro','office_raion','sport_objects_raion','raion_popul','healthcare_centers_raion',
            'school_education_centers_raion','preschool_education_centers_raion']
target_train=train['price_doc']
</script></div>
    <p>Create the distribution plot for the target</p>
<div class="linked"><script type="text/x-sage">
f,(ax1,ax2)=pylab.subplots(ncols=2,figsize=(11,5))
seaborn.distplot(target_train,bins=200,color='#228B22',ax=ax1)
ax1.set_xlabel("Prices"); ax1.set_ylabel("Distribution")
seaborn.distplot(numpy.log(target_train),bins=200,color='#228B22',ax=ax2)
ax2.set_xlabel("Logarithm of the variable 'Prices'"); ax2.set_ylabel("Distribution")
pylab.suptitle('Sberbank Russian Housing Data'); pylab.show()
</script></div>
    <p>Create the table of descriptive statistics</p>
<div class="linked"><script type="text/x-sage">
print ("Sberbank Russian Housing Dataset Statistics: \n")
print ("Number of houses = "+str(len(target_train)))
print ("Number of features = "+str(len(list(train[X_list_num+X_list_cat].keys()))))
print ("Minimum house price = "+str(numpy.min(target_train)))
print ("Maximum house price = "+str(numpy.max(target_train)))
print ("Mean house price = %.4f"%numpy.mean(target_train))
print ("Median house price = %.4f" %numpy.median(target_train))
print ("Standard deviation of house prices = %.4f"%numpy.std(target_train))
</script></div>
    <p></p>
    <h3>Fill in Missing Values</h3>
<div class="linked"><script type="text/x-sage">
pandas.DataFrame(train[X_list_num].isnull().sum(),columns=['nan'])
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
pandas.DataFrame(test[X_list_num].isnull().sum(),columns=['nan'])
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
df_train=pandas.DataFrame(train,columns=X_list_num)
df_train_cat=pandas.DataFrame(train,columns=X_list_num+X_list_cat)
df_test=pandas.DataFrame(test,columns=X_list_num)
df_test_cat=pandas.DataFrame(test,columns=X_list_num+X_list_cat)
df_train['prices']=target_train; df_train_cat['prices']=target_train
df_train=df_train.dropna(subset=['num_room'])
df_train_cat=df_train_cat.dropna(subset=['num_room'])
for el in ['metro_min_walk','railroad_station_walk_min']:
    for df in [df_train,df_train_cat,df_test,df_test_cat]:
        df[el]=df[el].interpolate(method='linear')
len(df_train),len(df_test)
</script></div>
    <p></p>
    <h3>Categorical and Macro Features</h3>
<h4>Add One Macro Feature</h4>
<div class="linked"><script type="text/x-sage">
usdrub_pairs=dict(zip(list(macro['timestamp']),list(macro['usdrub'])))
# salary_pairs=dict(zip(list(macro['timestamp']),list(macro['salary'])))
for df in [df_train,df_train_cat,df_test,df_test_cat]:
    df['timestamp'].replace(usdrub_pairs,inplace=True)
    df.rename(columns={'timestamp':'usdrub'},inplace=True)
</script></div>
    <p></p>
<h4>Explore numbers of categories and values for categorical features</h4>
<div class="linked"><script type="text/x-sage">
for feature in X_list_cat:
    display_cat(df_train_cat,feature)
</script></div>
    <p>Find the missing category in the testing set</p>
<div class="linked"><script type="text/x-sage">
for feature in X_list_cat:
    display_cat(df_test_cat,feature)
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
for feature in X_list_cat:
    for element in list(set(df_test_cat[feature])):
        if element not in list(set(df_train_cat[feature])): 
            print (feature,element)
</script></div>
    <p>Replace categorical values of 'ID_metro' by discrete numbers</p>
<div class="linked"><script type="text/x-sage">
ID_metro_cat=pandas.factorize(df_train_cat['ID_metro'])
ID_metro_pairs=dict(zip(list(ID_metro_cat[1]),list(set(ID_metro_cat[0])))); ID_metro_pairs[224]=219
df_train_cat['ID_metro']=ID_metro_cat[0]; df_test_cat['ID_metro'].replace(ID_metro_pairs,inplace=True)
</script></div>
    <p>Replace values of other categorical features by discrete numbers</p>
<div class="linked"><script type="text/x-sage">
for feature in X_list_cat:
    if feature!='ID_metro':
        feature_cat=pandas.factorize(df_train_cat[feature])
        feature_pairs=dict(zip(list(feature_cat[1]),list(set(feature_cat[0]))))
        df_train_cat[feature]=feature_cat[0]; df_test_cat[feature].replace(feature_pairs,inplace=True)
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
    <h3>Additional Code Cell</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p> 
  </body>
</html>