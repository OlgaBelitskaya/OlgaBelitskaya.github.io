<!DOCTYPE HTML>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=0.9*device-width">
    <title>MLE_ND_P3_SMC</title>
    <script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script>
    <script>$(function () {
    sagecell.makeSagecell({inputLocation:'div.linked',linked:true,evalButtonText:'Run Linked Cells'});  
    sagecell.makeSagecell({inputLocation:'div.sage',evalButtonText:'Run'});
    });
    </script>
  </head>
  <style>
  @import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');
  body {background-color:ghostwhite;}; a, p {color:#5a8bbd; font-family:'Roboto';} 
  h1 {color:#1b2c45; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;} 
  h2, h3 {color:slategray; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;}
  h4 {color:#1b2c45; font-family:'Roboto';}
  .sagecell .CodeMirror-scroll {min-height:3em; max-height:48em;}
  .sagecell table.table_form tr.row-a {background-color:lightgray;} 
  .sagecell table.table_form tr.row-b {background-color:ghostwhite;}
  .sagecell table.table_form td {padding:5px 15px; color:#5a8bbd; font-family:'Roboto';}
  .sagecell_sessionOutput, .sagecell_sessionOutput pre {color:#5a8bbd; font-family:'Roboto';}
  </style>  
  <body>
    <h1>Machine Learning Engineer Nanodegree</h1>
    <h2>Unsupervised Learning</h2>
    <h1>&#x1F4D1; &nbsp;P3: Creating Customer Segments</h1>
    <h2>Getting Started</h2>
    <h3>Dataset</h3>
In this project, we will analyze a dataset containing data on various customers' annual spending amounts (reported in monetary units) of diverse product categories for internal structure.<br/>
One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with.<br/>
Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.<br/>
The dataset for this project can be found on the <a href="https://archive.ics.uci.edu/ml/datasets/Wholesale+customers">&#x1F578;UCI Machine Learning Repository</a>.<br/> 
For the purposes of this project, the features <i>Channel</i> and <i>Region</i> will be excluded in the analysis — with focus instead on the six product categories recorded for customers.      
    <h3>Resources</h3>
<a href="http://archive.ics.uci.edu/ml/datasets.php">&#x1F578;UCI Machine Learning Repository&nbsp;</a>
<a href="https://scikit-learn.org/stable/index.html">&#x1F578;scikit-learn. Machine Learning in Python&nbsp;</a>
<a href="http://seaborn.pydata.org/index.html">&#x1F578;seaborn: statistical data visualization&nbsp;</a><br/>
    <h3>Code Library</h3> 
<div class="linked"><script type="text/x-sage">
import numpy,pandas,pylab,seaborn,time; pylab.style.use('seaborn-pastel')
import warnings; from sklearn.exceptions import DataConversionWarning
for el in [FutureWarning,UserWarning,DataConversionWarning]: warnings.filterwarnings("ignore",category=el)
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.tree import DecisionTreeRegressor; from sklearn.ensemble import RandomForestRegressor
from sklearn.decomposition import PCA; from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture; from sklearn.metrics import silhouette_score
</script></div>
    <p></p>      
<div class="linked"><script type="text/x-sage">
# https://github.com/udacity/machine-learning/blob/master/projects/customer_segments/visuals.py
def pca_results(good_data,pca):
    dimensions=['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]
    components=pandas.DataFrame(numpy.round(pca.components_,4),columns=good_data.keys())
    components.index=dimensions; ratios=pca.explained_variance_ratio_.reshape(len(pca.components_),1)
    variance_ratios=pandas.DataFrame(numpy.round(ratios,4),columns=['Explained Variance'])
    variance_ratios.index=dimensions 
    fig,ax=pylab.subplots(figsize=(12,5)); components.plot(ax=ax,kind='bar');
    ax.set_ylabel("Feature Weights",fontsize=12); ax.set_xticklabels(dimensions,rotation=0)
    for i,ev in enumerate(pca.explained_variance_ratio_):
        ax.text(i-0.40,ax.get_ylim()[1]+0.05,"Explained Variance \n %.4f"%(ev))
    pylab.show()
    return pandas.concat([variance_ratios,components],axis=1)
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
def cluster_results(reduced_data,preds,centers,pca_samples):
    predictions=pandas.DataFrame(preds,columns=['Cluster'])
    plot_data=pandas.concat([predictions,reduced_data],axis=1)
    fig,ax=pylab.subplots(figsize=(12,8))
    cmap=seaborn.cubehelix_palette(2,start=.1,rot=-.25,as_cmap=True)
    for i,cluster in plot_data.groupby('Cluster'):   
        cluster.plot(ax=ax,kind='scatter',x='Dimension 1',y='Dimension 2',
                     color=cmap((i)*1.0/(len(centers)-1)),label='Cluster %i'%(i),s=30);
    for i,c in enumerate(centers):
        ax.scatter(x=c[0],y=c[1],color='white',edgecolors='black',alpha=1,linewidth=2,marker='o',s=250);
        ax.scatter(x=c[0],y=c[1],marker='$%d$'%(i),alpha=1,s=120,color='black');
        ax.scatter(x=pca_samples[:,0],y=pca_samples[:,1],s=150,linewidth=4,color='black',marker='x');
    ax.set_title("Cluster Learning on PCA-Reduced Data\nCentroids Marked by Number\n\
    Transformed Sample Data Marked by Black Cross",fontsize=20); pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
def biplot(good_data,reduced_data,pca):
    fig,ax=pylab.subplots(figsize=(12,5))  
    ax.scatter(x=reduced_data.loc[:,'Dimension 1'],y=reduced_data.loc[:,'Dimension 2'], 
               facecolors='slategrey',edgecolors='1b2c45',s=70,alpha=0.5)
    feature_vectors=pca.components_.T
    arrow_size,text_pos=7.0,8.0
    for i,v in enumerate(feature_vectors):
        ax.arrow(0,0,arrow_size*v[0],arrow_size*v[1],head_width=0.2,head_length=0.2,linewidth=2,color='red')
        ax.text(v[0]*text_pos,v[1]*text_pos,good_data.columns[i],color='black',ha='center',va='center',fontsize=20)
    ax.set_xlabel("Dimension 1",fontsize=12); ax.set_ylabel("Dimension 2",fontsize=12)
    ax.set_title("PC plane with original feature projections.",fontsize=20); pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
def channel_results(reduced_data,outliers,pca_samples):
    path='https://raw.githubusercontent.com/OlgaBelitskaya/'+\
         'machine_learning_engineer_nd009/master/Machine_Learning_Engineer_ND_P3/'
    full_data=pandas.read_csv(path+'customers.csv')
    channel=pandas.DataFrame(full_data['Channel'],columns=['Channel'])
    channel=channel.drop(channel.index[outliers]).reset_index(drop=True)
    labeled=pandas.concat([reduced_data,channel],axis=1)
    fig,ax=pylab.subplots(figsize=(12,5))
    cmap=seaborn.cubehelix_palette(2,start=.1,rot=-.25,as_cmap=True)
    labels=['Hotel/Restaurant/Cafe','Retailer']; grouped=labeled.groupby('Channel')
    for i,channel in grouped:   
        channel.plot(ax=ax,kind='scatter',x='Dimension 1',y='Dimension 2',color=cmap((i-1)*1.0/2),label=labels[i-1],s=30)  
    for i,sample in enumerate(pca_samples):
        ax.scatter(x=sample[0],y=sample[1],s=230,linewidth=3,color='black',marker='o',facecolors='none');
        ax.scatter(x=sample[0]+0.25,y=sample[1]+0.3,marker='$%d$'%(i),alpha=1,s=200,color='black')
    ax.set_title("PCA-Reduced Data Labeled by 'Channel'\nTransformed Sample Data Circled",fontsize=20)
    pylab.show()
</script></div>
    <p></p>
    <h2>Data Exploration</h2>
In this section, we will begin exploring the data through visualizations and code to understand how each feature is related to the others.<br/>
We will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset<br/>which you will track through the course of this project.<br/>
The dataset is composed of six important product categories: <i>Fresh, Milk, Grocery, Frozen, Detergents_Paper</i>, and <i>Delicatessen</i>.<br/> 
Consider what each category represents in terms of products we could purchase.
    <h3>Data Loading</h3>    
<div class="linked"><script type="text/x-sage">
path='https://raw.githubusercontent.com/OlgaBelitskaya/machine_learning_engineer_nd009/master/Machine_Learning_Engineer_ND_P3/'
data=pandas.read_csv(path+'customers.csv'); data.drop(['Region','Channel'],axis=1,inplace=True)
print ("Wholesale customers dataset has {} samples with {} features each.".format(*data.shape))
data.describe()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
data.plot.area(stacked=False,figsize=(12,5)); pylab.grid(); pylab.show()
</script></div>
    <p></p>
    <h3>Implementation: Selecting Samples</h3>
To get a better understanding of the customers and how their data will transform through the analysis,<br/>
it would be best to select a few sample data points and explore them in more detail.<br/>
In the code block below, add three indices of your choice to the indices list which will represent the customers to track.<br/>
It is suggested to try different sets of samples until you obtain customers that vary significantly from one another.
<div class="linked"><script type="text/x-sage">
indices=[23,25,27]; samples=pandas.DataFrame(data.loc[indices],columns=data.keys()).reset_index(drop=True)
samples.index=['C0','C1','C2']; samples.loc['Mean']=samples.mean()
print ("Chosen samples of wholesale customers dataset:"); samples
#samples.T.plot(figsize=(12,5),colors=['#1b2c45','#5a8bbd','#008b8b','#ff5a8b'])
#pylab.grid(); pylab.show()
</script></div>
    <p></p>
    <p>Click “Run” twice. Use in HTML documents with &#60;/script&#62; in the end.</p>
<div class="sage"><script type="text/x-sage">
%%html
<script src="https://code.highcharts.com/highcharts.js"/><div id="test_highcharts" style="width:1200px;height:500px;"/><script>
Highcharts.chart('test_highcharts',{
    xAxis:{categories:['Fresh','Milk','Grocery','Frozen','Detergents_Paper','Delicatessen']},yAxis:{title:{text:'Value'}},
    title:{style:{'color':'#5a8bbd','fontSize':'24px'},text:'Chosen samples of wholesale customers dataset'},
    series:[{name:'C0',color:'#1b2c45',data:[26373,36423,22019,5154,4337,16523]},{name:'C1',color:'#5a8bbd',data:[16165,4230,7595,201,4003,57]},
            {name:'C2',color:'#008b8b',data:[14276,803,3045,485,100,518]},{name:'Mean',color:'#ff5a8b',data:[18938,13819,10886,1947,2813,5699]}]
},function(chart){var point=chart.series.data,
                  text=chart.renderer.text(point.plotX+chart.plotLeft+10,point.plotY+chart.plotTop-10).add(),box=text.getBBox();});
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
pylab.figure(figsize=(12,5)); p_samples=samples.iloc[:].T.apply(lambda x:100.0*x/x.sum())
cmap=seaborn.cubehelix_palette(2,start=.1,rot=-.25,as_cmap=True)
seaborn.heatmap(p_samples,cmap=cmap,annot=True,annot_kws={"color":"White","size":20},fmt='.1f')
pylab.title("Product categories in percentages for the sample customers",fontsize=15)
pylab.xticks(ha='center',fontsize=12); pylab.yticks(fontsize=10); pylab.show()
</script></div>
    <p></p>
<b>Customer C0</b> - food-oriented supermarket:<br/>
- the wide range of products with big values; <br/>
- the significant excess of the purchasing volumes of categories <i>Fresh, Milk</i> over others;<br/>
- the purchasing volumes of categories <i>Fresh, Grocery, Milk, Delicatessen</i> are much higher than the mean values;<br/>
- the categories <i>Detergents_Paper, Frozen</i> are close to the means values.<br/>
<b>Customer C1</b> - market for the nearest neighborhood:<br/>
- the highest purchasing volumes are in the category <i>Fresh</i>;<br/>
- the purchasing volumes of all categories are close to the mean values.<br/>
<b>Customer C2</b> - vegetarian cafe or restaurant:<br/>
- the significant excess of the purchasing volumes of the category <i>Fresh</i> over others;<br/>
- the purchasing volumes of categories <i>Frozen, Grocery, Milk, Detergents_Paper</i> are lower than the mean values;<br/>
- the purchasing volumes of the category <i>Detergents_Paper</i> are extremely small.
    <h3>Implementation: Feature Relevance</h3>
One interesting thought to consider is if one (or more) of the six product categories is actually relevant for understanding customer purchasing.<br/>
That is to say, is it possible to determine whether customers purchasing some amount of one category<br/> 
of products will necessarily purchase some proportional amount of another category of products?<br/> 
We can make this determination quite easily by training a supervised regression learner on a subset of the data with one feature removed,<br/>
and then score how well that model can predict the removed feature.<br/>
In the code block below, we will need to implement the following:<br/>
Assign <i>new_data</i> a copy of the data by removing a feature of our choice using the <i>DataFrame.drop</i> function.<br/>
Use <i>sklearn.model_selection.train_test_split</i> to split the dataset into training and testing sets.<br/>
&nbsp;&nbsp;Use the removed feature as our target label.<br/>
&nbsp;&nbsp;Set the <i>test_size</i> of 0.25 and set the <i>random_state</i> parameter.<br/>
      Import the <i>Decision Tree Regressor</i>, set the <i>random_state</i> parameter, and fit the learner to the training data.<br/>
Report the prediction score of the testing set using the regressor's score function.<br/>
    <h4>Experiment with <i>Delicatessen</i></h4>
<div class="linked"><script type="text/x-sage">
new_data=data.drop('Delicatessen',axis=1); target=data['Delicatessen']
new_data_target=pandas.concat([new_data,target],axis=1)
print ("The correlation table for the choosen feature 'Delicatessen'")
pearson=new_data_target.corr(method='pearson'); corr_with_delicatesse=pearson.iloc[-1][:-1]
corr_with_delicatessen[abs(corr_with_delicatessen).argsort()[::-1]]
</script></div>
    <p></p> 
<div class="linked"><script type="text/x-sage">
pylab.figure(figsize=(12,5)); seaborn.distplot(target,color='#1b2c45',bins=100,hist_kws={'color':'SlateGrey'})
pylab.xlabel("Delicatessen",fontsize=20); pylab.title("Customers' Annual Spending",fontsize=15);
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>      
    <h3>Additional Code Cell</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p> 
  </body>
</html>