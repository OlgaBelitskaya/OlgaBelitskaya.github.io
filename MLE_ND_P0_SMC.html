<!DOCTYPE HTML>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=0.9*device-width">
    <title>MLE_ND_P0_SMC</title>
    <script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script>
    <script>$(function () {
    sagecell.makeSagecell({inputLocation:'div.linked',linked:true,evalButtonText:'Run Linked Cells'});
    sagecell.makeSagecell({inputLocation:'div.sage_html',evalButtonText:'Run HTML'});  
    sagecell.makeSagecell({inputLocation:'div.sage_r',evalButtonText:'Run R'});  
    sagecell.makeSagecell({inputLocation:'div.sage',evalButtonText:'Run'});
    });
    </script>
  </head>
  <style>
  @import url('https://fonts.googleapis.com/css?family=Orbitron|Roboto');
  body {background-color:oldlace;}; a {color:darksalmon; font-family:'Roboto';} 
  h1 {color:#ff603b; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;} 
  h2,h3 {color:slategray; font-family:'Orbitron'; text-shadow:4px 4px 4px #ccc;}
  h4 {color:#ff603b; font-family:'Roboto';}
  .sagecell .CodeMirror-scroll {min-height:3em; max-height:48em;}
  </style>  
  <body>
    <h1>Machine Learning Engineer Nanodegree</h1>
    <h2>Introduction and Foundations</h2>
    <h1>&#x1F4D1; &nbsp;P0: Titanic Survival Exploration</h1>
In 1912, the ship RMS Titanic struck an iceberg on its maiden voyage and sank, resulting in the deaths of most of its passengers and crew.<br/>
In this introductory project, we will explore a subset of the RMS Titanic passenger manifest to determine<br/>
which features best predict whether someone survived or did not survive.
    <h2>Getting Started</h2>
    <h3>Resources</h3>
<a href="https://www.udacity.com/course/intro-to-data-science--ud359">Intro to Data Science. Udacity</a>
<a href="http://scipy-lectures.org/packages/statistics/index.html">Statistics in Python. Scipy Lecture Notes</a>
<a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A Visual Introduction to Machine Learning. Part 1</a>
<a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">The scikit-learn metrics</a>
    <h3>Code Tools</h3>
<div class="linked"><script type="text/x-sage">
import numpy,pandas,pylab; pylab.style.use('ggplot')
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
# https://github.com/udacity/machine-learning/blob/master/projects/titanic_survival_exploration/visuals.py
def filter_data(data,condition):
    field,sign,value=condition.split(" ")
    try: value=float(value)
    except: value=value.strip("\'\"")
    if sign==">": exp=data[field]>value
    elif sign=="<": exp=data[field]<value
    elif sign==">=": exp=data[field]>=value
    elif sign=="<=": exp=data[field]<=value
    elif sign=="==": exp=data[field]==value
    elif sign=="!=": exp= data[field]!=value
    else: raise Exception("Invalid comparison operator. Only >, <, >=, <=, ==, != allowed.")
    return data[matches].reset_index(drop=True)    
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
def survival_stats(data,outcomes,key,filters=[]):
    if (key not in data.columns.values):
        print ("'{}' is not a feature of the Titanic data. Did you spell something wrong?".format(key)); return False
    if (key=='Cabin' or key=='PassengerId' or key=='Ticket'):
        print ("'{}' has too many unique categories to display! Try a different feature.".format(key)); return False
    all_data=pandas.concat([data,outcomes],axis=1)
    for condition in filters: all_data=filter_data(all_data,condition)
    all_data=all_data[[key,'Survived']]; pylab.figure(figsize=(12,5))
    if (key=='Age' or key=='Fare'):
        all_data=all_data[~numpy.isnan(all_data[key])]
        min_value=all_data[key].min(); max_value=all_data[key].max(); value_range=max_value-min_value
        if(key=='Fare'): bins=numpy.arange(0,all_data['Fare'].max()+20,20)
        if(key=='Age'): bins=numpy.arange(0,all_data['Age'].max()+10,10)
        nonsurv_vals=all_data[all_data['Survived']==0][key].reset_index(drop=True)
        surv_vals=all_data[all_data['Survived']==1][key].reset_index(drop=True)
        pylab.hist(nonsurv_vals,bins=bins,alpha=0.6,color='#FF7F50',label='Did not survive')
        pylab.hist(surv_vals,bins=bins,alpha=0.6,color='#338DD4',label='Survived')
        pylab.xlim(0,bins.max()); pylab.legend(framealpha=0.8)
    else:
        if (key=='Pclass'): values=numpy.arange(1,4)
        if (key=='Parch' or key=='SibSp'): values=numpy.arange(0,numpy.max(data[key])+1)
        if (key=='Embarked'): values=['C','Q','S']
        if (key=='Sex'): values=['male','female']
        frame=pandas.DataFrame(index=numpy.arange(len(values)),columns=(key,'Survived','NSurvived'))
        for i,value in enumerate(values):
            frame.loc[i]=[value,len(all_data[(all_data['Survived']==1) & (all_data[key]==value)]),
                          len(all_data[(all_data['Survived']==0) & (all_data[key]==value)])]
        bar_width=0.4
        for i in numpy.arange(len(frame)):
            nonsurv_bar =pylab.bar(i-bar_width,frame.loc[i]['NSurvived'],width=bar_width,color='#FF7F50')
            surv_bar=plt.bar(i,frame.loc[i]['Survived'],width=bar_width,color='#338DD4')
            pylab.xticks(np.arange(len(frame)),values)
            pylab.legend((nonsurv_bar[0],surv_bar[0]),('Did not survive','Survived'),framealpha=0.8)
    pylab.xlabel(key); pylab.ylabel('Number of Passengers')
    pylab.title('Passenger Survival Statistics With \'%s\' Feature'%(key)); pylab.show()
    if sum(pandas.isnull(all_data[key])):
        nan_outcomes=all_data[pandas.isnull(all_data[key])]['Survived']
        print ("Passengers with missing '{}' values: {} ({} survived, {} did not survive)"\
               .format(key,len(nan_outcomes),sum(nan_outcomes==1),sum(nan_outcomes==0)))
</script></div>
    <p></p>
To begin working with the RMS Titanic passenger data, we'll first need to import the functionality we need, and load our data into a pandas DataFrame.
<br/>
Run the code cell below to load our data and display the first few entries (passengers) for examination using the .head() function.
<div class="linked"><script type="text/x-sage">
path='https://raw.githubusercontent.com/OlgaBelitskaya/machine_learning_engineer_nd009/master/Machine_Learning_Engineer_ND_P0/'
full_data=pandas.read_csv(path+'titanic_data.csv'); full_data.head()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
full_data.info();
</script></div>
    <p></p>
From a sample of the RMS Titanic data, we can see the various features present for each passenger on the ship:<br/>
<b>Survived:</b> Outcome of survival (0 = No; 1 = Yes)<br/>
<b>Pclass:</b> Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)<br/>
<b>Name:</b> Name of passenger<br/>
<b>Sex:</b> Sex of the passenger<br/>
<b>Age:</b> Age of the passenger (Some entries contain NaN)<br/>
<b>SibSp:</b> Number of siblings and spouses of the passenger aboard<br/>
<b>Parch:</b> Number of parents and children of the passenger aboard<br/>
<b>Ticket:</b> Ticket number of the passenger<br/>
<b>Fare:</b> Fare paid by the passenger<br/>
<b>Cabin:</b> Cabin number of the passenger (Some entries contain NaN)<br/>
<b>Embarked:</b> Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)<br/>
Since we're interested in the outcome of survival for each passenger or crew member,<br/>
we can remove the <b>Survived</b> feature from this dataset and store it as its own separate variable outcomes.<br/> 
We will use these outcomes as our prediction targets.      
<div class="linked"><script type="text/x-sage">
outcomes=full_data['Survived']; data=full_data.drop('Survived',axis=1); full_data.head()
</script></div>
    <p></p>
The very same sample of the RMS Titanic data now shows the <b>Survived</b> feature removed from the DataFrame.<br/>
Note that the passenger data and the outcomes of survival are now paired. That means for any passenger <b>data.loc[i]</b>, they have the survival <b>outcomes[i]</b>.<br/>
To measure the performance of our predictions, we need a metric to score our predictions against the true outcomes of survival - the function accuracy_score(). Since we are interested in how accurate our predictions are, we will calculate the proportion of passengers where our prediction of their survival is correct.<br/>
<b>Think:</b> Out of the first five passengers, if we predict that all of them survived, what would you expect the accuracy of our predictions to be?      
<div class="linked"><script type="text/x-sage">
def accuracy_score(truth, pred):
    if len(truth)==len(pred): 
        return "Predictions have an accuracy of {:.2f}%.".format((truth==pred).mean()*100)    
    else:
        return "Number of predictions does not match number of outcomes!"
predictions=pandas.Series(numpy.ones(5,dtype=int)); accuracy_score(outcomes[:5],predictions)
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
  </body>
</html>