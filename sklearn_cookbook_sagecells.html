<!DOCTYPE HTML>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=0.9*device-width">
    <title>SklearnCookbook</title>
    <script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script>
    <script>$(function () {
    sagecell.makeSagecell({inputLocation:'div.linked',linked:true,evalButtonText:'Run Linked Cells'});
    sagecell.makeSagecell({inputLocation:'div.sage',evalButtonText:'Run'});
    sagecell.makeSagecell({inputLocation:'div.sage_html',evalButtonText:'Run HTML'});
    });
    </script>
  </head>
  <style>
  @import url('https://fonts.googleapis.com/css?family=Ewert|Roboto&effect=ice');
  h1, h2 {color:slategray; font-family:'Ewert'; font-size:130%; text-shadow:5px 5px 5px #aaa;}
  h3, h4 {color:darkslategray; font-family:'Roboto'; text-shadow:5px 5px 5px #aaa;}
  p, a {color:darkblue; font-size:110%; text-shadow:5px 5px 5px #aaa;}
  .sagecell .CodeMirror-scroll {min-height:3em; max-height:30em;}   
  </style>  
  <body>
    <h1>&#x1F4D1; &nbsp; Scikit-Learn Cookbook</h1>
    <p>Load Python libraries for all linked cells</p>
<div class="linked"><script type="text/x-sage">
import numpy,pandas,scipy,pylab,h5py,urllib,zipfile
from sklearn import datasets,preprocessing,cluster,mixture,manifold,dummy,linear_model,svm
from sklearn.feature_extraction import DictVectorizer 
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_selection import SelectKBest,chi2,RFE
from sklearn.decomposition import PCA; from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,median_absolute_error,mean_absolute_error,r2_score,explained_variance_score
from sklearn.metrics import accuracy_score,hamming_loss,classification_report
from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier,DecisionTreeRegressor,ExtraTreeRegressor
from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier
from sklearn.ensemble import BaggingRegressor,RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor,RadiusNeighborsRegressor
from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier,NearestCentroid
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB
from sklearn.kernel_ridge import KernelRidge
from sklearn.cross_decomposition import PLSRegression
from sklearn.gaussian_process import GaussianProcessRegressor,GaussianProcessClassifier
from sklearn.gaussian_process.kernels import WhiteKernel,RationalQuadratic,RBF
from sklearn.semi_supervised import LabelPropagation,LabelSpreading
from sklearn.isotonic import IsotonicRegression
from sklearn.neural_network import MLPClassifier,BernoulliRBM,MLPRegressor
</script></div>
    <p></p>
    <h2 class="font-effect-ice">Data</h2>
    <h3>internal datasets</h3>
<div class="linked"><script type="text/x-sage">
boston=datasets.load_boston(); housing=datasets.fetch_california_housing()
digits=datasets.load_digits(); wine=datasets.load_wine();
faces=datasets.fetch_olivetti_faces(); covtype=datasets.fetch_covtype()
[X1,y1,X2,y2,X3,y3,X4,y4,X5,y5,X6,y6]=\
[boston.data,boston.target,housing.data,housing.target,digits.data,digits.target,
wine.data,wine.target,faces.data,faces.target,covtype.data,covtype.target]
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
n=4; img=numpy.zeros((10*n,10*n))
for i in range(n): 
    for j in range(n): 
        img[(10*i+1):(10*i+9),(10*j+1):(10*j+9)]=X3[i*n+j].reshape((8,8))
pylab.figure(figsize=(5,5)); pylab.imshow(img,cmap=pylab.cm.bone)
pylab.title('Examples of 64-dimensional digits')
pylab.xticks([]); pylab.yticks([]); pylab.show()
</script></div>
    <p></p>
    <h3>artificial datasets</h3>
<div class="linked"><script type="text/x-sage">
# 5000x3 matrix, 3 features (2 responsible for targets), 1 target, 0.97 - the bias factor
[X7,y7]=datasets.make_regression(5000,3,2,1,0.97)
f,ax=pylab.subplots(ncols=3,figsize=(12,5)); k=[[0,1],[0,2],[1,2]]
[ax[i].scatter(X7[:200,k[i][0]], X7[:200,k[i][1]],c=y7[:200],cmap=pylab.cm.tab10) for i in range(3)]
[ax[i].set_xlabel('X7[%d]'%k[i][0]) for i in range(3)]; [ax[i].set_ylabel('X7[%d]'%k[i][1]) for i in range(3)]
pylab.show()
# 5000x10 matrix, 10 features (8 - responsible for targets), 2 targets, 0.7 - the bias factor, 10.0 - the noise
[X8,y8]=datasets.make_regression(5000,10,8,2,0.7,noise=10.0)
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
# Gaussian blobs for clustering, 1000 data points, 4 clusters
[X9,y9]=datasets.make_blobs(n_samples=1000,centers=[[1,1],[-1,-1],[1,-1],[-1,1]],cluster_std=0.5)
pylab.figure(figsize=(12,5)); pylab.scatter(X9[:,0],X9[:,1],c=y9,cmap=pylab.cm.tab10)
pylab.scatter([1,-1,1,-1],[1,-1,-1,1],c='black',marker='*',s=150); pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
# 5000 data points, 2 features, 1 target with 3 labels
[X10,y10]=datasets.make_multilabel_classification(n_classes=3,n_samples=5000,n_features=2)
f,ax=pylab.subplots(1,figsize=(12,5)); m=['o','v','*']; a=[0.2,0.5,1]; s=[800,400,200]
[ax.scatter(X10[:30,0],X10[:30,1],c=y10[:30,i],marker=m[i],alpha=a[i],cmap=pylab.cm.bwr,s=s[i]) for i in range(3)]
pylab.show()
</script></div>
    <p></p>
    <h3>external datasets</h3>
<div class="linked"><script type="text/x-sage">
se=pandas.read_json('https://data.cityofnewyork.us/resource/h7rb-945c.json')
feature_list=['dbn','ell_programs','language_classes','finalgrades','total_students',
              'graduation_rate','attendance_rate','college_career_rate','pct_stu_safe',
              'pct_stu_enough_variety','latitude','longitude','council_district','city']
se=se[feature_list].dropna(); f,ax=pylab.subplots(ncols=3,figsize=(12,5))
for i in range(3):
    se[feature_list[i+5]]=se[feature_list[i+5]].astype('string').str.replace("N/A","0").astype('float')
    se.plot(kind="scatter",x="longitude",y="latitude",s=10,c=feature_list[i+5],cmap=pylab.cm.jet,ax=ax[i],alpha=0.8)
    ax[i].set_xticks([]); ax[i].set_yticks([]);
pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
user="https://raw.githubusercontent.com/OlgaBelitskaya/"
path="machine_learning_engineer_nd009/master/Machine_Learning_Engineer_ND_P3/"
data=pandas.read_csv(user+path+"customers.csv"); data.drop(['Region','Channel'],axis=1,inplace=True)
data.plot.area(stacked=False,figsize=(12,5),grid=True); 
pylab.title('Data Values by Product Categories'); pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
path='https://olgabelitskaya.github.io/'; zf='LetterColorImages_123.h5.zip'
input_file=urllib.urlopen(path+zf); output_file=open(zf,'wb'); 
output_file.write(input_file.read()); output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r'); zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r'); keys=list(f.keys()); letters=u'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
backgrounds=numpy.array(f[keys[0]]); letter_images=numpy.array(f[keys[1]])/255; targets=numpy.array(f[keys[2]])
print(letters[targets[2000]-1]); pylab.figure(figsize=(5,5)); pylab.xticks([]); pylab.yticks([]); 
pylab.imshow(letter_images[2000]); pylab.show()
</script></div>
    <p></p>
<div class="linked"><script type="text/x-sage">
path='https://olgabelitskaya.github.io/'; zf='StyleColorImages.h5.zip'
input_file=urllib.urlopen(path+zf); output_file=open(zf,'wb'); 
output_file.write(input_file.read()); output_file.close(); input_file.close()
zipf=zipfile.ZipFile(zf,'r'); zipf.extractall(''); zipf.close()
f=h5py.File(zf[:-4],'r'); keys=list(f.keys()); 
brands=numpy.array(f[keys[0]]); style_images=numpy.array(f[keys[1]])/255; products=numpy.array(f[keys[2]])
print(brands[1000],products[1000]); pylab.figure(figsize=(5,5)); pylab.xticks([]); pylab.yticks([]); 
pylab.imshow(style_images[1000]); pylab.show()
</script></div>
    <p></p>
    <h2 class="font-effect-ice">Extraction and Preprocessing</h2>
    <h3>extraction</h3>
<div class="linked"><script type="text/x-sage">
temperature=[{'city':'Hanoi','temperature':33.},{'city':'Frankfurt','temperature':16.},{'city':'Houston','temperature':28.},
             {'city':'Riyadh','temperature':38.},{'city':'Barcelona','temperature':17.},{'city':'Ankara','temperature':27.}]
corpus=['Have you already set your goals for the New Year?','Do you want to lose ten kilos, run a marathon or speak fluent English?', 
        'Some experts believe that you need systems, not goals.','A system is something you do on a regular basis.',
        'This means focusing on what you can control (your actions) rather than what you can’t.',
        'For example, do not focus on losing ten kilos.','Focus on shopping for healthy food and cooking something light every day.',
        'Do not focus on the marathon.','Focus on the training schedule.',
        'Invent a system to improve your English, one step at a time.','Good luck!']
dv=DictVectorizer(); temperature_features=dv.fit_transform(temperature).toarray().astype('int16')
pretty_print([temperature_features,dv.get_feature_names()])
cv=CountVectorizer(min_df=1); corpus_features=cv.fit_transform(corpus)
corpus_array=corpus_features.toarray().astype('int16'); c_analyzer=cv.build_analyzer()
import pylab; pylab.figure(figsize=(12,5))
for i in range(len(corpus_array)): pylab.scatter(range(len(corpus_array[i])),(corpus_array[i]*0.5+i),marker='s')
pylab.title("The Words' Occurrence in Sentences",fontsize=15); pylab.show()
print(c_analyzer(corpus[0]))
</script></div>
    <p></p>
    <h3>scaling</h3>
<div class="linked"><script type="text/x-sage">
SCX1=[X1,preprocessing.MinMaxScaler().fit_transform(X1),preprocessing.MaxAbsScaler().fit_transform(X1),
      preprocessing.StandardScaler().fit_transform(X1),preprocessing.RobustScaler().fit_transform(X1)]
n=50; pylab.figure(figsize=(12,5)); m=['*','v','^','<','>']
labels=['Real Data','MinMax Scaler','MaxAbs Scaler','Standard Scaler','Robust Scaler']
for i in range(5): pylab.scatter(range(n),SCX1[i][:n,4],marker=m[i],label=labels[i])
pylab.legend(loc=8); pylab.show()
</script></div>      
    <p></p>
    <h3>one-hot encoding</h3>
<div class="linked"><script type="text/x-sage">
def ohe(x): return preprocessing.OneHotEncoder(categories='auto').fit(x.reshape(-1,1)).transform(x.reshape(-1,1)).toarray().astype('int16')
cat_brands ,cat_products,cat_backgrounds,cat_targets=ohe(brands),ohe(products),ohe(backgrounds),ohe(targets)
pretty_print([targets[99:102],'=>',cat_targets[99:102]])
</script></div>
    <p></p>
    <h3>imputation of missing values</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
    <h3>features' importance</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
    <h3>dimensionality reduction</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
    <h3>shuffling and splitting</h3>
<div class="linked"><script type="text/x-sage">

</script></div>
    <p></p>
    <h2 class="font-effect-ice">Additional Cells</h2>  
<div class="sage"><script type="text/x-sage">

</script></div>
    <p></p>   
<div class="sage"><script type="text/x-sage">

</script></div>
    <p></p>
  </body>
</html>